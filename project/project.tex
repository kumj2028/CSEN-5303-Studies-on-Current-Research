\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url}
\usepackage[colorlinks]{hyperref}
\usepackage{listings}
\usepackage{tikz}
\usepackage{tkz-euclide}
\usepackage{svg}

\usetikzlibrary{shapes,positioning,shapes.gates.logic}

\tikzset{ell/.style={circle,draw,minimum height=0.2cm,minimum width=0.2cm,inner sep=0.15cm}}
\tikzset{rec/.style={rectangle,draw,minimum height=0.5cm,minimum width=0.5cm,inner sep=0.2cm}}
\tikzset{trp/.style={trapezium,draw,trapezium left angle=120, trapezium right angle=120, minimum height=0.5cm}}


%New colors defined below
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

%Code listing style named "mystyle"
\lstdefinestyle{mystyle}{
  backgroundcolor=\color{backcolour}, commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2
}

%"mystyle" code listing set
\lstset{style=mystyle}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Improving GPT Penetration Testing Using Prompt Engineering Techniques
\thanks{}
}
\author{\IEEEauthorblockN{Daniel Lichtenberger}
\IEEEauthorblockA{\textit{Department of EECS} \\
\textit{Texas A\&M University-Kingsville}\\
Kingsville, USA \\
daniel.lichtenberger@students.tamuk.edu
}
\and
\IEEEauthorblockN{Mengxiang Jiang}
\IEEEauthorblockA{\textit{Department of EECS} \\
\textit{Texas A\&M University-Kingsville}\\
Kingsville, USA \\
mengxiang.jiang@students.tamuk.edu}
\and
\IEEEauthorblockN{Samah Allahyani}
\IEEEauthorblockA{\textit{Department of EECS} \\
\textit{Texas A\&M University-Kingsville}\\
Kingsville, USA \\
samah.allahyani@students.tamuk.edu}
}

\maketitle

\begin{abstract}
    With the introduction of GPT4 in early 2023, many researchers discovered capabilities of the LLM that were in the past lacking. One of these capabilities is penetration testing in the field of cybersecurity. This allows security experts to automate a large part of the vulnerability exploration process since many of the tasks required are fairly routine. A framework for doing this called PentestGPT which was able to perform at the top 1\% of users at the penetration test website HackTheBox. However, it still had difficulties tackling the more difficult servers on the site. In this paper we use some general purpose prompt engineering techniques to see if there are improvements to the penetration testing results.
\end{abstract}

\section{introduction} \label{sec:intro}
ChatGPT is a large language model (LLM) that generates automated responses that correlates with a response asked by users\cite{engman2023evaluation}. ChatGPT itself exploded in popularity that sparked greater curiosity in the field of artificial intelligence. The model itself has accumulated an information dataset that has expanded in more recent iterations with GPT-4 \cite{hariri2023unlocking}. Apart from ChatGPT, LLMs are becoming an investment that could affect the lives of people depending on their use and accessibility. Cybersecurity is one field that is currently being explored with LLMs such as ChatGPT. Penetration testing is one such topic in the realm of cybersecurity that is being tested with ChatGPT and the results that the model produces.

Penetration testing started as a need to combat cybercrime from a dynamically involved cybersecurity environment\cite{deng2023pentestgpt}. From 2021, the FBI reported that data breaches caused monetary damages up to \$6.9 billion dollars\cite{heim2023convergence}.  Pentesting is becoming more of a demand as companies desire to have protection in case of an emergency. The process is very intensive and requires a dedicated security team to carry out methodical processes to complete\cite{applebaum2017analysis}. There are different levels of penetration testing known as white-box, black-box, and gray-box determined by the amount of knowledge from the system in question\cite{deng2023pentestgpt}. The incorporation of large language models like ChatGPT could help improve pentesting methods on a targeted system. A LLM known as PentestGPT uses ChatGPT for its methods, and will have a structured purpose for our analysis\cite{deng2023pentestgpt}.

Lately, there has been significant advancement in LLMs, demonstrating refined and nuanced comprehension of human-like text and proficiently completing a variety of tasks in multiple fields\cite{zhao2023survey}\cite{liu2023summary}. An interesting characteristic of LLMs is their emergent capabilities—capabilities not directly coded but developed during training\cite{wei2022emergent}. This enables them to undertake sophisticated tasks like reasoning, summarizing, answering questions, and solving domain-specific problems without the need for task-specific training. These capabilities highlight the transformative possibilities of LLMs in several sectors, cybersecurity and penetration testing in particular.

A mixture that both utilizes AI and penetration testing is a model called PentestGPT\cite{heim2023convergence}. PentestGPT is a recently created framework that demonstrates pentesting capabilities by inputting generated responses from ChatGPT into making an automated penetration testing machine \cite{deng2023pentestgpt}. The framework uses 3 modules independent from one another to keep information on track while knowing token limitations on ChatGPT. Each module serves a purpose in conducting responses suitable to their role relatable to a penetration testing team. The modules follow a step-by-step process in order to successfully output a suitable response. The reasoning module passes its results to the generation module, and ends with the parsing module getting information from the generation module. PentestGPT showed promising results for 4 out of the 10 targeted HackTheBox\cite{hackthebox} machines at a cost of 131.5 US dollars, which is in the top 1\% of users on the site. It already utilizes a technique called prompt engineering, which we will discuss in the next paragraph, but there seems to be room for improvement\cite{white2023prompt}.

Similar to human dialogues, conversations can take multiple diverse directions. Within the realm of ChatGPT, this variability has spawned a novel research field known as prompt engineering. This field is concentrated on devising methods to create prompts that yield the most accurate and valuable responses, and it remains a burgeoning science. White et al. created a catalog of various prompt engineering patterns in order to improve the results of these conversations\cite{white2023prompt}. We will employ some of these patterns for the purpose of improving penetration testing.

\section{Proposed Approaches} \label{sec:approach}
In this section, we will cover the various prompt engineering techniques used to improve GPT4's penetration test performance.

\subsection{Flipped Interaction Pattern} \label{ssec:flipped}
One of the first steps of a penetration test is intelligence gathering\cite{ptes}. During this stage, the primary goal is to collect as much information as possible about the target system without actively engaging with it. This information will be used in later stages of the penetration test to identify vulnerabilities and potential attack vectors. Rather than manually going through the list of activities prescribed by the Penetration Testing Execution Standard (PTES), having the LLM ask the tester for information is a more active way of achieving this step. The Flipped Interaction Pattern is having the LLM drive the conversation and automatically ask questions until it has sufficient information to.complete a task or proceed to the next step \cite{white2023prompt}. For our purposes, an example prompt to initialize this is: “I would like you to ask me questions to do the reconnaissance step of a penetration test following the Penetration Testing Execution Standard. When you have enough information, notify me in order to proceed to the next stage.”

\subsection{Persona Pattern} \label{ssec:persona}
Often, users prefer the output of LLMs to maintain a consistent perspective or stance. For instance, performing a penetration test with the LLM acting as a cybersecurity expert could be beneficial. The purpose of this approach is to assign a “persona” to the LLM, guiding it in determining the kind of responses to generate and the specifics to emphasize\cite{white2023prompt}. Pentest GPT already does this with initializing its core modules, with a prompt starting with “You're an excellent cybersecurity penetration tester assistant”\cite{deng2023pentestgpt}. We will employ a similar persona pattern

\subsection{Game Play Pattern} \label{ssec:gameplay}
A penetration testing environment can be applied in ChatGPT by treating it as a game. The pattern can create a game around the topic the user specifies. This prompt pattern utilizes a interchangeable combination of the persona, infinite generation, and visualization generator patterns\cite{white2023prompt}. With this pattern, the user can add contextual statements regarding what game rules ChatGPT is supposed to follow. Imposing restrictions during the game creates an influx of interesting generated responses. For example, we could have ChatGPT act as a Linux terminal to play a game where our role is to pentest the system. ChatGPT may provide a backdoor with our HacktheBox machines if we keep the game play engaging enough to automate a sufficient response. We will use this pattern into PentestGPT to analyze its results from penetration testing environments.

\bibliographystyle{plain}
\bibliography{project}

\vspace{12pt}

\end{document}
